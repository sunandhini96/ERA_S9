# ERA_S9
## Task : CIFAR -10 image classification

The CIFAR-10 dataset is a widely used benchmark dataset for image classification tasks in computer vision. It consists of 60,000 color images, each of size 32x32 pixels, divided into 10 different classes. The dataset is evenly split into 50,000 training images and 10,000 test images.

## Visualization :

![image](https://github.com/sunandhini96/ERA_S9/assets/63030539/d32e0aa6-7756-4c2f-b7fc-95ec39228a6d)

## Summary of model :

<img width="422" alt="image" src="https://github.com/sunandhini96/ERA_S9/assets/63030539/bd3dd42a-bdfd-4ce5-bb82-daf71d8377fe">

<img width="398" alt="image" src="https://github.com/sunandhini96/ERA_S9/assets/63030539/b8832fb0-bd8c-478c-96fa-429a1e57396d">

## Training logs : over 40 epochs

EPOCH: 0
Loss=1.4477176666259766 Batch_id=2499 Accuracy=42.07: 100%|██████████| 2500/2500 [00:51<00:00, 48.68it/s]

Test set: Average loss: 1.2062, Accuracy: 5647/10000 (56.47%)

EPOCH: 1
Loss=0.7445029020309448 Batch_id=2499 Accuracy=54.19: 100%|██████████| 2500/2500 [00:40<00:00, 61.32it/s]

Test set: Average loss: 1.0482, Accuracy: 6254/10000 (62.54%)

EPOCH: 2
Loss=1.3236591815948486 Batch_id=2499 Accuracy=59.10: 100%|██████████| 2500/2500 [00:43<00:00, 56.86it/s]

Test set: Average loss: 0.9421, Accuracy: 6678/10000 (66.78%)

EPOCH: 3
Loss=1.0979433059692383 Batch_id=2499 Accuracy=62.55: 100%|██████████| 2500/2500 [00:44<00:00, 55.96it/s]

Test set: Average loss: 0.8445, Accuracy: 7066/10000 (70.66%)

EPOCH: 4
Loss=0.7958625555038452 Batch_id=2499 Accuracy=65.12: 100%|██████████| 2500/2500 [00:43<00:00, 56.89it/s]

Test set: Average loss: 0.7915, Accuracy: 7263/10000 (72.63%)

EPOCH: 5
Loss=1.191933512687683 Batch_id=2499 Accuracy=67.36: 100%|██████████| 2500/2500 [00:41<00:00, 60.46it/s]

Test set: Average loss: 0.7324, Accuracy: 7430/10000 (74.30%)

EPOCH: 6
Loss=1.0778263807296753 Batch_id=2499 Accuracy=71.64: 100%|██████████| 2500/2500 [00:41<00:00, 59.80it/s]

Test set: Average loss: 0.6620, Accuracy: 7691/10000 (76.91%)

EPOCH: 7
Loss=0.6711398363113403 Batch_id=2499 Accuracy=72.75: 100%|██████████| 2500/2500 [00:42<00:00, 58.86it/s]

Test set: Average loss: 0.6499, Accuracy: 7733/10000 (77.33%)

EPOCH: 8
Loss=0.6924811601638794 Batch_id=2499 Accuracy=73.26: 100%|██████████| 2500/2500 [00:41<00:00, 59.62it/s]

Test set: Average loss: 0.6493, Accuracy: 7755/10000 (77.55%)

EPOCH: 9
Loss=1.0327197313308716 Batch_id=2499 Accuracy=73.44: 100%|██████████| 2500/2500 [00:41<00:00, 59.89it/s]

Test set: Average loss: 0.6445, Accuracy: 7758/10000 (77.58%)

EPOCH: 10
Loss=0.6760246753692627 Batch_id=2499 Accuracy=73.70: 100%|██████████| 2500/2500 [00:42<00:00, 58.80it/s]

Test set: Average loss: 0.6218, Accuracy: 7842/10000 (78.42%)

EPOCH: 11
Loss=0.6267181038856506 Batch_id=2499 Accuracy=74.14: 100%|██████████| 2500/2500 [00:41<00:00, 60.76it/s]

Test set: Average loss: 0.6272, Accuracy: 7838/10000 (78.38%)

EPOCH: 12
Loss=0.3734281063079834 Batch_id=2499 Accuracy=74.55: 100%|██████████| 2500/2500 [00:40<00:00, 62.21it/s]

Test set: Average loss: 0.6264, Accuracy: 7825/10000 (78.25%)

EPOCH: 13
Loss=0.5710800886154175 Batch_id=2499 Accuracy=74.77: 100%|██████████| 2500/2500 [00:40<00:00, 61.86it/s]

Test set: Average loss: 0.6282, Accuracy: 7818/10000 (78.18%)

EPOCH: 14
Loss=0.41047829389572144 Batch_id=2499 Accuracy=74.94: 100%|██████████| 2500/2500 [00:40<00:00, 62.50it/s]

Test set: Average loss: 0.6213, Accuracy: 7840/10000 (78.40%)

EPOCH: 15
Loss=0.8619778752326965 Batch_id=2499 Accuracy=74.98: 100%|██████████| 2500/2500 [00:40<00:00, 61.86it/s]

Test set: Average loss: 0.6205, Accuracy: 7850/10000 (78.50%)

EPOCH: 16
Loss=0.4443906843662262 Batch_id=2499 Accuracy=74.81: 100%|██████████| 2500/2500 [00:42<00:00, 59.10it/s]

Test set: Average loss: 0.6133, Accuracy: 7860/10000 (78.60%)

EPOCH: 17
Loss=0.9082814455032349 Batch_id=2499 Accuracy=74.87: 100%|██████████| 2500/2500 [00:39<00:00, 62.65it/s]

Test set: Average loss: 0.6132, Accuracy: 7858/10000 (78.58%)

EPOCH: 18
Loss=0.8627544641494751 Batch_id=2499 Accuracy=75.03: 100%|██████████| 2500/2500 [00:39<00:00, 62.74it/s]

Test set: Average loss: 0.6129, Accuracy: 7870/10000 (78.70%)

EPOCH: 19
Loss=0.6837628483772278 Batch_id=2499 Accuracy=74.81: 100%|██████████| 2500/2500 [00:38<00:00, 64.22it/s]

Test set: Average loss: 0.6178, Accuracy: 7858/10000 (78.58%)

EPOCH: 20
Loss=0.35010239481925964 Batch_id=2499 Accuracy=75.05: 100%|██████████| 2500/2500 [00:40<00:00, 62.40it/s]

Test set: Average loss: 0.6093, Accuracy: 7876/10000 (78.76%)

EPOCH: 21
Loss=0.673524022102356 Batch_id=2499 Accuracy=74.88: 100%|██████████| 2500/2500 [00:41<00:00, 60.82it/s]

Test set: Average loss: 0.6089, Accuracy: 7885/10000 (78.85%)

EPOCH: 22
Loss=0.8565679788589478 Batch_id=2499 Accuracy=74.60: 100%|██████████| 2500/2500 [00:40<00:00, 62.40it/s]

Test set: Average loss: 0.6124, Accuracy: 7863/10000 (78.63%)

EPOCH: 23
Loss=0.6207696795463562 Batch_id=2499 Accuracy=74.95: 100%|██████████| 2500/2500 [00:40<00:00, 62.01it/s]

Test set: Average loss: 0.6159, Accuracy: 7862/10000 (78.62%)

EPOCH: 24
Loss=0.9910368919372559 Batch_id=2499 Accuracy=75.00: 100%|██████████| 2500/2500 [00:39<00:00, 62.61it/s]

Test set: Average loss: 0.6230, Accuracy: 7849/10000 (78.49%)

EPOCH: 25
Loss=0.535527229309082 Batch_id=2499 Accuracy=74.95: 100%|██████████| 2500/2500 [00:40<00:00, 60.99it/s]

Test set: Average loss: 0.6130, Accuracy: 7856/10000 (78.56%)

EPOCH: 26
Loss=0.39001351594924927 Batch_id=2499 Accuracy=75.09: 100%|██████████| 2500/2500 [00:40<00:00, 62.38it/s]

Test set: Average loss: 0.6177, Accuracy: 7874/10000 (78.74%)

EPOCH: 27
Loss=0.6399223804473877 Batch_id=2499 Accuracy=75.12: 100%|██████████| 2500/2500 [00:42<00:00, 59.38it/s]

Test set: Average loss: 0.6125, Accuracy: 7885/10000 (78.85%)

EPOCH: 28
Loss=0.7416540384292603 Batch_id=2499 Accuracy=75.05: 100%|██████████| 2500/2500 [00:42<00:00, 59.51it/s]

Test set: Average loss: 0.6232, Accuracy: 7835/10000 (78.35%)

EPOCH: 29
Loss=0.6271716356277466 Batch_id=2499 Accuracy=74.82: 100%|██████████| 2500/2500 [00:42<00:00, 58.81it/s]

Test set: Average loss: 0.6152, Accuracy: 7862/10000 (78.62%)

EPOCH: 30
Loss=0.5710423588752747 Batch_id=2499 Accuracy=74.87: 100%|██████████| 2500/2500 [00:42<00:00, 58.26it/s]

Test set: Average loss: 0.6156, Accuracy: 7848/10000 (78.48%)

EPOCH: 31
Loss=0.6686573624610901 Batch_id=2499 Accuracy=75.30: 100%|██████████| 2500/2500 [00:42<00:00, 59.03it/s]

Test set: Average loss: 0.6080, Accuracy: 7875/10000 (78.75%)

EPOCH: 32
Loss=0.6097737550735474 Batch_id=2499 Accuracy=75.08: 100%|██████████| 2500/2500 [00:41<00:00, 59.63it/s]

Test set: Average loss: 0.6208, Accuracy: 7854/10000 (78.54%)

EPOCH: 33
Loss=0.579014241695404 Batch_id=2499 Accuracy=75.16: 100%|██████████| 2500/2500 [00:41<00:00, 60.53it/s]

Test set: Average loss: 0.6113, Accuracy: 7855/10000 (78.55%)

EPOCH: 34
Loss=0.27706533670425415 Batch_id=2499 Accuracy=74.91: 100%|██████████| 2500/2500 [00:42<00:00, 58.79it/s]

Test set: Average loss: 0.6144, Accuracy: 7851/10000 (78.51%)

EPOCH: 35
Loss=0.7016671895980835 Batch_id=2499 Accuracy=74.98: 100%|██████████| 2500/2500 [00:42<00:00, 59.18it/s]

Test set: Average loss: 0.6126, Accuracy: 7859/10000 (78.59%)

EPOCH: 36
Loss=0.7023204565048218 Batch_id=2499 Accuracy=75.05: 100%|██████████| 2500/2500 [00:41<00:00, 59.75it/s]

Test set: Average loss: 0.6189, Accuracy: 7841/10000 (78.41%)

EPOCH: 37
Loss=0.6442255973815918 Batch_id=2499 Accuracy=74.99: 100%|██████████| 2500/2500 [00:41<00:00, 59.72it/s]

Test set: Average loss: 0.6130, Accuracy: 7862/10000 (78.62%)

EPOCH: 38
Loss=0.6742684841156006 Batch_id=2499 Accuracy=75.11: 100%|██████████| 2500/2500 [00:42<00:00, 58.79it/s]

Test set: Average loss: 0.6093, Accuracy: 7879/10000 (78.79%)

EPOCH: 39
Loss=0.8128570318222046 Batch_id=2499 Accuracy=74.81: 100%|██████████| 2500/2500 [00:42<00:00, 58.61it/s]

Test set: Average loss: 0.6188, Accuracy: 7854/10000 (78.54%)

## Training and validation Loss and accuracy curves :

![image](https://github.com/sunandhini96/ERA_S9/assets/63030539/9fffafbb-2763-4f6c-9023-1327cf10b1e4)

Observations : We trained the model over 40 epochs test accuracy around 79 % it's not varying so much.






