# ERA_S9
## Task : CIFAR -10 image classification

The CIFAR-10 dataset is a widely used benchmark dataset for image classification tasks in computer vision. It consists of 60,000 color images, each of size 32x32 pixels, divided into 10 different classes. The dataset is evenly split into 50,000 training images and 10,000 test images.

## Visualization

![image](https://github.com/sunandhini96/ERA_S9/assets/63030539/05203716-d229-46c0-b0d1-869b5e85c676)


## Summary of model :

<img width="445" alt="image" src="https://github.com/sunandhini96/ERA_S9/assets/63030539/7bc321bb-7ff6-42ed-8e7f-bcd45c8ee737">

<img width="431" alt="image" src="https://github.com/sunandhini96/ERA_S9/assets/63030539/cd98b976-f125-44b1-8a60-43946458b088">


## Training logs : over 50 epochs

EPOCH: 0
Loss=1.5757849216461182 Batch_id=97 Accuracy=33.80: 100%|██████████| 98/98 [00:22<00:00,  4.41it/s]

Test set: Average loss: 1.5012, Accuracy: 4462/10000 (44.62%)

EPOCH: 1
Loss=1.4008125066757202 Batch_id=97 Accuracy=46.31: 100%|██████████| 98/98 [00:20<00:00,  4.67it/s]

Test set: Average loss: 1.2715, Accuracy: 5320/10000 (53.20%)

EPOCH: 2
Loss=1.282279372215271 Batch_id=97 Accuracy=52.95: 100%|██████████| 98/98 [00:22<00:00,  4.33it/s]

Test set: Average loss: 1.2141, Accuracy: 5653/10000 (56.53%)

EPOCH: 3
Loss=1.1450014114379883 Batch_id=97 Accuracy=56.37: 100%|██████████| 98/98 [00:22<00:00,  4.32it/s]

Test set: Average loss: 1.0374, Accuracy: 6258/10000 (62.58%)

EPOCH: 4
Loss=1.0916813611984253 Batch_id=97 Accuracy=59.44: 100%|██████████| 98/98 [00:21<00:00,  4.58it/s]

Test set: Average loss: 0.9412, Accuracy: 6674/10000 (66.74%)

EPOCH: 5
Loss=1.0559911727905273 Batch_id=97 Accuracy=61.97: 100%|██████████| 98/98 [00:20<00:00,  4.70it/s]

Test set: Average loss: 0.8952, Accuracy: 6836/10000 (68.36%)

EPOCH: 6
Loss=1.0382226705551147 Batch_id=97 Accuracy=64.31: 100%|██████████| 98/98 [00:20<00:00,  4.77it/s]

Test set: Average loss: 0.8471, Accuracy: 7024/10000 (70.24%)

EPOCH: 7
Loss=0.947790801525116 Batch_id=97 Accuracy=65.83: 100%|██████████| 98/98 [00:21<00:00,  4.64it/s]

Test set: Average loss: 0.7665, Accuracy: 7282/10000 (72.82%)

EPOCH: 8
Loss=0.9242296814918518 Batch_id=97 Accuracy=67.05: 100%|██████████| 98/98 [00:21<00:00,  4.60it/s]

Test set: Average loss: 0.7646, Accuracy: 7308/10000 (73.08%)

EPOCH: 9
Loss=0.9834792017936707 Batch_id=97 Accuracy=68.37: 100%|██████████| 98/98 [00:21<00:00,  4.57it/s]

Test set: Average loss: 0.7805, Accuracy: 7296/10000 (72.96%)

EPOCH: 10
Loss=0.9432013630867004 Batch_id=97 Accuracy=69.32: 100%|██████████| 98/98 [00:20<00:00,  4.74it/s]

Test set: Average loss: 0.6843, Accuracy: 7606/10000 (76.06%)

EPOCH: 11
Loss=0.8871675133705139 Batch_id=97 Accuracy=70.33: 100%|██████████| 98/98 [00:20<00:00,  4.70it/s]

Test set: Average loss: 0.6749, Accuracy: 7635/10000 (76.35%)

EPOCH: 12
Loss=0.8986826539039612 Batch_id=97 Accuracy=71.01: 100%|██████████| 98/98 [00:21<00:00,  4.58it/s]

Test set: Average loss: 0.6903, Accuracy: 7617/10000 (76.17%)

EPOCH: 13
Loss=0.8089399933815002 Batch_id=97 Accuracy=71.78: 100%|██████████| 98/98 [00:21<00:00,  4.52it/s]

Test set: Average loss: 0.6261, Accuracy: 7811/10000 (78.11%)

EPOCH: 14
Loss=0.7297646403312683 Batch_id=97 Accuracy=72.61: 100%|██████████| 98/98 [00:21<00:00,  4.54it/s]

Test set: Average loss: 0.6223, Accuracy: 7857/10000 (78.57%)

EPOCH: 15
Loss=0.7751535773277283 Batch_id=97 Accuracy=72.78: 100%|██████████| 98/98 [00:20<00:00,  4.85it/s]

Test set: Average loss: 0.6011, Accuracy: 7920/10000 (79.20%)

EPOCH: 16
Loss=0.8007113337516785 Batch_id=97 Accuracy=73.07: 100%|██████████| 98/98 [00:20<00:00,  4.83it/s]

Test set: Average loss: 0.6000, Accuracy: 7942/10000 (79.42%)

EPOCH: 17
Loss=0.6645008325576782 Batch_id=97 Accuracy=73.79: 100%|██████████| 98/98 [00:21<00:00,  4.58it/s]

Test set: Average loss: 0.5840, Accuracy: 7985/10000 (79.85%)

EPOCH: 18
Loss=0.8452221751213074 Batch_id=97 Accuracy=74.07: 100%|██████████| 98/98 [00:21<00:00,  4.59it/s]

Test set: Average loss: 0.6037, Accuracy: 7911/10000 (79.11%)

EPOCH: 19
Loss=0.7903329730033875 Batch_id=97 Accuracy=74.55: 100%|██████████| 98/98 [00:20<00:00,  4.81it/s]

Test set: Average loss: 0.5618, Accuracy: 8053/10000 (80.53%)

EPOCH: 20
Loss=0.7770638465881348 Batch_id=97 Accuracy=74.93: 100%|██████████| 98/98 [00:20<00:00,  4.87it/s]

Test set: Average loss: 0.5784, Accuracy: 8021/10000 (80.21%)

EPOCH: 21
Loss=0.6116175651550293 Batch_id=97 Accuracy=75.07: 100%|██████████| 98/98 [00:21<00:00,  4.60it/s]

Test set: Average loss: 0.5646, Accuracy: 8075/10000 (80.75%)

EPOCH: 22
Loss=0.6473553776741028 Batch_id=97 Accuracy=75.78: 100%|██████████| 98/98 [00:21<00:00,  4.59it/s]

Test set: Average loss: 0.5583, Accuracy: 8110/10000 (81.10%)

EPOCH: 23
Loss=0.6496868133544922 Batch_id=97 Accuracy=76.04: 100%|██████████| 98/98 [00:21<00:00,  4.62it/s]

Test set: Average loss: 0.5260, Accuracy: 8173/10000 (81.73%)

EPOCH: 24
Loss=0.7345458269119263 Batch_id=97 Accuracy=76.17: 100%|██████████| 98/98 [00:20<00:00,  4.87it/s]

Test set: Average loss: 0.5383, Accuracy: 8188/10000 (81.88%)

EPOCH: 25
Loss=0.6171005964279175 Batch_id=97 Accuracy=76.46: 100%|██████████| 98/98 [00:20<00:00,  4.83it/s]

Test set: Average loss: 0.5232, Accuracy: 8183/10000 (81.83%)

EPOCH: 26
Loss=0.5854296088218689 Batch_id=97 Accuracy=76.82: 100%|██████████| 98/98 [00:21<00:00,  4.61it/s]

Test set: Average loss: 0.5173, Accuracy: 8251/10000 (82.51%)

EPOCH: 27
Loss=0.6181892156600952 Batch_id=97 Accuracy=77.21: 100%|██████████| 98/98 [00:21<00:00,  4.54it/s]

Test set: Average loss: 0.5383, Accuracy: 8152/10000 (81.52%)

EPOCH: 28
Loss=0.6208509802818298 Batch_id=97 Accuracy=77.47: 100%|██████████| 98/98 [00:20<00:00,  4.80it/s]

Test set: Average loss: 0.5265, Accuracy: 8189/10000 (81.89%)

EPOCH: 29
Loss=0.5899529457092285 Batch_id=97 Accuracy=77.51: 100%|██████████| 98/98 [00:20<00:00,  4.87it/s]

Test set: Average loss: 0.5022, Accuracy: 8262/10000 (82.62%)

EPOCH: 30
Loss=0.7028959393501282 Batch_id=97 Accuracy=77.72: 100%|██████████| 98/98 [00:21<00:00,  4.59it/s]

Test set: Average loss: 0.4982, Accuracy: 8290/10000 (82.90%)

EPOCH: 31
Loss=0.6226779222488403 Batch_id=97 Accuracy=78.07: 100%|██████████| 98/98 [00:21<00:00,  4.61it/s]

Test set: Average loss: 0.5082, Accuracy: 8266/10000 (82.66%)

EPOCH: 32
Loss=0.5788058042526245 Batch_id=97 Accuracy=77.96: 100%|██████████| 98/98 [00:20<00:00,  4.76it/s]

Test set: Average loss: 0.5061, Accuracy: 8276/10000 (82.76%)

EPOCH: 33
Loss=0.6330087780952454 Batch_id=97 Accuracy=78.34: 100%|██████████| 98/98 [00:20<00:00,  4.85it/s]

Test set: Average loss: 0.4865, Accuracy: 8322/10000 (83.22%)

EPOCH: 34
Loss=0.6951746940612793 Batch_id=97 Accuracy=78.81: 100%|██████████| 98/98 [00:20<00:00,  4.72it/s]

Test set: Average loss: 0.4938, Accuracy: 8334/10000 (83.34%)

EPOCH: 35
Loss=0.5794070363044739 Batch_id=97 Accuracy=78.65: 100%|██████████| 98/98 [00:21<00:00,  4.61it/s]

Test set: Average loss: 0.4763, Accuracy: 8361/10000 (83.61%)

EPOCH: 36
Loss=0.6278604865074158 Batch_id=97 Accuracy=78.70: 100%|██████████| 98/98 [00:21<00:00,  4.56it/s]

Test set: Average loss: 0.4824, Accuracy: 8360/10000 (83.60%)

EPOCH: 37
Loss=0.5048085451126099 Batch_id=97 Accuracy=79.01: 100%|██████████| 98/98 [00:20<00:00,  4.76it/s]

Test set: Average loss: 0.4795, Accuracy: 8384/10000 (83.84%)

EPOCH: 38
Loss=0.598193347454071 Batch_id=97 Accuracy=78.99: 100%|██████████| 98/98 [00:20<00:00,  4.75it/s]

Test set: Average loss: 0.4691, Accuracy: 8412/10000 (84.12%)

EPOCH: 39
Loss=0.6966530680656433 Batch_id=97 Accuracy=79.21: 100%|██████████| 98/98 [00:21<00:00,  4.62it/s]

Test set: Average loss: 0.4744, Accuracy: 8372/10000 (83.72%)

EPOCH: 40
Loss=0.6283212304115295 Batch_id=97 Accuracy=79.26: 100%|██████████| 98/98 [00:21<00:00,  4.53it/s]

Test set: Average loss: 0.4608, Accuracy: 8446/10000 (84.46%)

EPOCH: 41
Loss=0.6217731833457947 Batch_id=97 Accuracy=79.76: 100%|██████████| 98/98 [00:21<00:00,  4.50it/s]

Test set: Average loss: 0.4547, Accuracy: 8475/10000 (84.75%)

EPOCH: 42
Loss=0.5750888586044312 Batch_id=97 Accuracy=79.80: 100%|██████████| 98/98 [00:20<00:00,  4.80it/s]

Test set: Average loss: 0.4612, Accuracy: 8428/10000 (84.28%)

EPOCH: 43
Loss=0.6153951287269592 Batch_id=97 Accuracy=79.79: 100%|██████████| 98/98 [00:20<00:00,  4.79it/s]

Test set: Average loss: 0.4544, Accuracy: 8442/10000 (84.42%)

EPOCH: 44
Loss=0.5760239958763123 Batch_id=97 Accuracy=80.04: 100%|██████████| 98/98 [00:21<00:00,  4.59it/s]

Test set: Average loss: 0.4388, Accuracy: 8491/10000 (84.91%)

EPOCH: 45
Loss=0.5456974506378174 Batch_id=97 Accuracy=80.25: 100%|██████████| 98/98 [00:21<00:00,  4.53it/s]

Test set: Average loss: 0.4557, Accuracy: 8459/10000 (84.59%)

EPOCH: 46
Loss=0.5574885010719299 Batch_id=97 Accuracy=80.28: 100%|██████████| 98/98 [00:21<00:00,  4.59it/s]

Test set: Average loss: 0.4388, Accuracy: 8519/10000 (85.19%)

EPOCH: 47
Loss=0.5154080390930176 Batch_id=97 Accuracy=80.73: 100%|██████████| 98/98 [00:20<00:00,  4.80it/s]

Test set: Average loss: 0.4446, Accuracy: 8474/10000 (84.74%)

EPOCH: 48
Loss=0.6603943109512329 Batch_id=97 Accuracy=80.42: 100%|██████████| 98/98 [00:20<00:00,  4.76it/s]

Test set: Average loss: 0.4364, Accuracy: 8502/10000 (85.02%)

EPOCH: 49
Loss=0.4878547787666321 Batch_id=97 Accuracy=80.82: 100%|██████████| 98/98 [00:21<00:00,  4.56it/s]

Test set: Average loss: 0.4318, Accuracy: 8524/10000 (85.24%)


## Training and validation Loss and accuracy curves :

![image](https://github.com/sunandhini96/ERA_S9/assets/63030539/ae0824ce-c42d-43b6-bd1a-74e919a7e5e5)


Observations : Here we applied dilation rate and also depthwise separable in our model less than 200K parameters. We trained the model over 50 epochs test accuracy reached our target accuracy of around 85 %.






